{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fJ4JAfmuPJC7",
   "metadata": {
    "id": "fJ4JAfmuPJC7"
   },
   "source": [
    "# Initializing the setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82528ac9-5f34-4b07-bf0c-fe20202618a9",
   "metadata": {
    "id": "82528ac9-5f34-4b07-bf0c-fe20202618a9"
   },
   "outputs": [],
   "source": [
    "!pip install openai==0.28\n",
    "import pandas as pd\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8jWzpVRL2jI",
   "metadata": {
    "id": "b8jWzpVRL2jI"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f69062-8bbb-4fe6-8e59-1e8e29a5601a",
   "metadata": {
    "id": "67f69062-8bbb-4fe6-8e59-1e8e29a5601a"
   },
   "outputs": [],
   "source": [
    "openai.api_key = ### OPENAI API KEY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GvDFvzpDPgzx",
   "metadata": {
    "id": "GvDFvzpDPgzx"
   },
   "source": [
    "# Define annotation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899cZG1ZejOE",
   "metadata": {
    "id": "899cZG1ZejOE"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yeys7hS26ryi",
   "metadata": {
    "id": "Yeys7hS26ryi"
   },
   "outputs": [],
   "source": [
    "def generate_tweet(claim, task, model, temperature=1, max_tokens=256, reversed=False):\n",
    "    if reversed==False:\n",
    "        # Set the prompt based on the task\n",
    "        if task in ['E', 'entailment', 'entail']:\n",
    "            instruction = \"Generate TWEET so that if CLAIM is true, then TWEET is also true. Be brief. Do not start a sentence with 'Just'.\"\n",
    "            prompt = f\"CLAIM: {claim}\\nTWEET:\"\n",
    "\n",
    "        elif task in ['C', 'contradiction', 'contradict']:\n",
    "            instruction = \"Generate TWEET so that if CLAIM is true, TWEET is false. Be brief. Do not start a sentence with 'Just'.\"\n",
    "            prompt = f\"CLAIM: {claim}\\nTWEET:\"\n",
    "\n",
    "        elif task in ['N', 'neutral']:\n",
    "            instruction = \"Generate TWEET so that even if CLAIM is true, TWEET cannot be said to be true or false. Be brief. Do not start a sentence with 'Just'. Use keywords from CLAIM.\"\n",
    "            prompt = f\"CLAIM: {claim}\\nTWEET:\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid task value.\")\n",
    "\n",
    "    else:\n",
    "        # Set the prompt based on the task\n",
    "        if task in ['E', 'entailment', 'entail']:\n",
    "            instruction = \"Generate TWEET so that if TWEET is true, then CLAIM is also true. Be brief. Do not start a sentence with 'Just'.\"\n",
    "            prompt = f\"CLAIM: {claim}\\nTWEET:\"\n",
    "\n",
    "        elif task in ['C', 'contradiction', 'contradict']:\n",
    "            instruction = \"Generate TWEET so that if TWEET is true, CLAIM is false. Be brief. Do not start a sentence with 'Just'.\"\n",
    "            prompt = f\"CLAIM: {claim}\\nTWEET:\"\n",
    "\n",
    "        elif task in ['N', 'neutral']:\n",
    "            instruction = \"Generate TWEET so that even if TWEET is true, CLAIM cannot be said to be true or false. Be brief. Do not start a sentence with 'Just'. Use keywords from CLAIM.\"\n",
    "            prompt = f\"CLAIM: {claim}\\nTWEET:\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid task value.\")\n",
    "\n",
    "    if model[0:3] == 'gpt':\n",
    "        # Generate the response using OpenAI's API\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": instruction},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    elif model[0:5] == 'Llama' or model[0:5] == 'llama':\n",
    "\n",
    "        if model.find('70b') >= 0:\n",
    "            llama = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "        elif model.find('13b') >= 0:\n",
    "            llama = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "        elif model.find('7b') >= 0:\n",
    "            llama = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "        else:\n",
    "            print('No model size found. Defaults to Llama-2-70b-chat-hf')\n",
    "\n",
    "        TOKEN = ### HUGGINGFACE API KEY ###\n",
    "        tokens=250\n",
    "        input = f\"\"\"<s>[INST] <<SYS>> {instruction} <</SYS>> {prompt} [/INST]\"\"\"\n",
    "\n",
    "        url = f'https://api-inference.huggingface.co/models/{llama}'\n",
    "        headers = {\n",
    "                \"Content-type\": \"application/json\",\n",
    "                \"Authorization\": f'Bearer {TOKEN}',\n",
    "            }\n",
    "        body = {\n",
    "                \"inputs\": input,\n",
    "\n",
    "                \"parameters\": {\"temperature\": 1,\n",
    "                              \"max_new_tokens\": tokens,\n",
    "                              \"return_full_text\": False},\n",
    "            }\n",
    "\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(body))\n",
    "        return response.json()[0]['generated_text'].strip().split('\\n')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obCrCUb_QK6_",
   "metadata": {
    "id": "obCrCUb_QK6_"
   },
   "source": [
    "# Testing with prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IE1I1DZogW91",
   "metadata": {
    "id": "IE1I1DZogW91"
   },
   "outputs": [],
   "source": [
    "model = 'llama-70b'\n",
    "model.find('7b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0nWPn0dZOcen",
   "metadata": {
    "id": "0nWPn0dZOcen"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "claim = \"Vaccininated people emit Bluetooth signals.\"\n",
    "\n",
    "entail = generate_tweet(claim, 'E', 'gpt-4')\n",
    "print(entail)\n",
    "\n",
    "entail_reversed = generate_tweet(claim, 'E', 'gpt-4', reversed=False)\n",
    "print(entail_reversed)\n",
    "\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4_RO3GBPG7",
   "metadata": {
    "id": "0a4_RO3GBPG7"
   },
   "source": [
    "# Open dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0r1ioxLBk18",
   "metadata": {
    "id": "c0r1ioxLBk18"
   },
   "outputs": [],
   "source": [
    "load_path = 'data/data_final.csv'\n",
    "save_path = 'data/data.csv'\n",
    "\n",
    "df = pd.read_csv(load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3r7_tN9Sigv",
   "metadata": {
    "id": "a3r7_tN9Sigv"
   },
   "source": [
    "# Annotation loop (original order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ZKP2hc2kKU8",
   "metadata": {
    "id": "6ZKP2hc2kKU8"
   },
   "source": [
    "### gpt-4 generation (orginal order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0547ae-7164-4391-86e3-e4401a3ad584",
   "metadata": {
    "id": "4f0547ae-7164-4391-86e3-e4401a3ad584"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    claim = row['claim']\n",
    "    retry = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        try:\n",
    "            if pd.isnull(row['generated_entail_tweet_gpt-4']):\n",
    "                df.at[i, 'generated_entail_tweet_gpt-4'] = generate_tweet(claim, 'E', 'gpt-4')\n",
    "\n",
    "            if pd.isnull(row['generated_contradict_tweet_gpt-4']):\n",
    "                df.at[i, 'generated_contradict_tweet_gpt-4'] = generate_tweet(claim, 'C', 'gpt-4')\n",
    "\n",
    "            if pd.isnull(row['generated_neutral_tweet_gpt-4']):\n",
    "                df.at[i, 'generated_neutral_tweet_gpt-4'] = generate_tweet(claim, 'N', 'gpt-4')\n",
    "\n",
    "            if pd.isnull(row['generated_entail_tweet_70b']):\n",
    "                df.at[i, 'generated_entail_tweet_70b'] = generate_tweet(claim, 'E', 'llama_2_70b')\n",
    "\n",
    "            if pd.isnull(row['generated_contradict_tweet_70b']):\n",
    "                df.at[i, 'generated_contradict_tweet_70b'] = generate_tweet(claim, 'C', 'llama_2_70b')\n",
    "\n",
    "            if pd.isnull(row['generated_neutral_tweet_70b']):\n",
    "                df.at[i, 'generated_neutral_tweet_70b'] = generate_tweet(claim, 'N', 'llama_2_70b')\n",
    "\n",
    "            if pd.isnull(row['generated_entail_tweet_gpt-3_5']):\n",
    "                df.at[i, 'generated_entail_tweet_gpt-3_5'] = generate_tweet(claim, 'E', 'gpt-3.5-turbo')\n",
    "\n",
    "            if pd.isnull(row['generated_contradict_tweet_gpt-3_5']):\n",
    "                df.at[i, 'generated_contradict_tweet_gpt-3_5'] = generate_tweet(claim, 'C', 'gpt-3.5-turbo')\n",
    "\n",
    "            if pd.isnull(row['generated_neutral_tweet_gpt-3_5']):\n",
    "                df.at[i, 'generated_neutral_tweet_gpt-3_5'] = generate_tweet(claim, 'N', 'gpt-3.5-turbo')\n",
    "\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(10)\n",
    "            retry += 1\n",
    "            if retry >= 50:\n",
    "                break\n",
    "\n",
    "    df.to_csv(save_path)\n",
    "\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    print(f\"Iteration: {i+1}, Runtime: {runtime} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JhK3suDOukL9",
   "metadata": {
    "id": "JhK3suDOukL9"
   },
   "source": [
    "### gpt-4 generation (reverse order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kT48jTh8ugPV",
   "metadata": {
    "id": "kT48jTh8ugPV"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    claim = row['claim']\n",
    "    retry = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        try:\n",
    "            if pd.isnull(row['generated_entail_tweet_reversed_gpt-4']):\n",
    "                df.at[i, 'generated_entail_tweet_reversed_gpt-4'] = generate_tweet(claim, 'E', 'gpt-4')\n",
    "\n",
    "            if pd.isnull(row['generated_contradict_tweet_reversed_gpt-4']):\n",
    "                df.at[i, 'generated_contradict_tweet_reversed_gpt-4'] = generate_tweet(claim, 'C', 'gpt-4')\n",
    "\n",
    "            if pd.isnull(row['generated_neutral_tweet_reversed_gpt-4']):\n",
    "                df.at[i, 'generated_neutral_tweet_reversed_gpt-4'] = generate_tweet(claim, 'N', 'gpt-4')\n",
    "\n",
    "            if pd.isnull(row['generated_entail_tweet_reversed_70b']):\n",
    "                df.at[i, 'generated_entail_tweet_reversed_70b'] = generate_tweet(claim, 'E', 'llama_2_70b')\n",
    "\n",
    "            if pd.isnull(row['generated_contradict_tweet_reversed_70b']):\n",
    "                df.at[i, 'generated_contradict_tweet_reversed_70b'] = generate_tweet(claim, 'C', 'llama_2_70b')\n",
    "\n",
    "            if pd.isnull(row['generated_neutral_tweet_reversed_70b']):\n",
    "                df.at[i, 'generated_neutral_tweet_reversed_70b'] = generate_tweet(claim, 'N', 'llama_2_70b')\n",
    "\n",
    "            if pd.isnull(row['generated_entail_tweet_reversed_gpt-3_5']):\n",
    "                df.at[i, 'generated_entail_tweet_reversed_gpt-3_5'] = generate_tweet(claim, 'E', 'gpt-3.5-turbo')\n",
    "\n",
    "            if pd.isnull(row['generated_contradict_tweet_reversed_gpt-3_5']):\n",
    "                df.at[i, 'generated_contradict_tweet_reversed_gpt-3_5'] = generate_tweet(claim, 'C', 'gpt-3.5-turbo')\n",
    "\n",
    "            if pd.isnull(row['generated_neutral_tweet_reversed_gpt-3_5']):\n",
    "                df.at[i, 'generated_neutral_tweet_reversed_gpt-3_5'] = generate_tweet(claim, 'N', 'gpt-3.5-turbo')\n",
    "\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(10)\n",
    "            retry += 1\n",
    "            if retry >= 50:\n",
    "                break\n",
    "\n",
    "    df.to_csv(save_path)\n",
    "\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    print(f\"Iteration: {i+1}, Runtime: {runtime} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B_TWLWS8M1aA",
   "metadata": {
    "id": "B_TWLWS8M1aA"
   },
   "source": [
    "# Additional index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BUj9079pMS0U",
   "metadata": {
    "id": "BUj9079pMS0U"
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MUZXRmuyiqmp",
   "metadata": {
    "id": "MUZXRmuyiqmp"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "a = len(df)\n",
    "x = list(range(a))\n",
    "random.Random(42).shuffle(x)\n",
    "entailment_add_index = x[:int(a * 1/2 - a * 1/3)]\n",
    "neutral_add_index = x[int(a * 1/2 - a * 1/3):int((a * 1/2 - a * 1/3) + (a * 35/100 - a * 1/3))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z1ucgMeyjLRB",
   "metadata": {
    "id": "z1ucgMeyjLRB"
   },
   "source": [
    "# Additional annotation for unbalanced train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Tjv_U0vYjO9q",
   "metadata": {
    "id": "Tjv_U0vYjO9q"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i, row in df.iterrows():\n",
    "    claim = row['claim']\n",
    "    retry = 0\n",
    "\n",
    "    if i in entailment_add_index:\n",
    "\n",
    "        while True:\n",
    "\n",
    "            try:\n",
    "                if pd.isnull(row['generated_entail_tweet_gpt-4_added']):\n",
    "                    df.at[i, 'generated_entail_tweet_gpt-4_added'] = generate_tweet(claim, 'E', 'gpt-4')\n",
    "\n",
    "                if pd.isnull(row['generated_entail_tweet_reversed_gpt-4_added']):\n",
    "                    df.at[i, 'generated_entail_tweet_reversed_gpt-4_added'] = generate_tweet(claim, 'E', 'gpt-4', reversed=True)\n",
    "\n",
    "                if pd.isnull(row['generated_entail_tweet_gpt-3_5_added']):\n",
    "                    df.at[i, 'generated_entail_tweet_gpt-3_5_added'] = generate_tweet(claim, 'E', 'gpt-3.5-turbo')\n",
    "\n",
    "                if pd.isnull(row['generated_entail_tweet_reversed_gpt-3_5_added']):\n",
    "                    df.at[i, 'generated_entail_tweet_reversed_gpt-3_5_added'] = generate_tweet(claim, 'E', 'gpt-3.5-turbo', reversed=True)\n",
    "\n",
    "                if pd.isnull(row['generated_entail_tweet_llama_2_70b_added']):\n",
    "                    df.at[i, 'generated_entail_tweet_llama_2_70b_added'] = generate_tweet(claim, 'E', 'llama-70b')\n",
    "\n",
    "                if pd.isnull(row['generated_entail_tweet_reversed_llama_2_70b_added']):\n",
    "                    df.at[i, 'generated_entail_tweet_reversed_llama_2_70b_added'] = generate_tweet(claim, 'E', 'llama_2_70b', reversed=True)\n",
    "\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                time.sleep(10)\n",
    "                retry += 1\n",
    "                if retry >= 50:\n",
    "                    break\n",
    "\n",
    "    elif i in neutral_add_index:\n",
    "\n",
    "        while True:\n",
    "\n",
    "            try:\n",
    "                if pd.isnull(row['generated_neutral_tweet_gpt-4_added']):\n",
    "                    df.at[i, 'generated_neutral_tweet_gpt-4_added'] = generate_tweet(claim, 'N', 'gpt-4')\n",
    "\n",
    "                if pd.isnull(row['generated_neutral_tweet_reversed_gpt-4_added']):\n",
    "                    df.at[i, 'generated_neutral_tweet_reversed_gpt-4_added'] = generate_tweet(claim, 'N', 'gpt-4', reversed=True)\n",
    "\n",
    "                if pd.isnull(row['generated_neutral_tweet_gpt-3_5_added']):\n",
    "                    df.at[i, 'generated_neutral_tweet_gpt-3_5_added'] = generate_tweet(claim, 'N', 'gpt-3.5-turbo')\n",
    "\n",
    "                if pd.isnull(row['generated_neutral_tweet_reversed_gpt-3_5_added']):\n",
    "                    df.at[i, 'generated_neutral_tweet_reversed_gpt-3_5_added'] = generate_tweet(claim, 'N', 'gpt-3.5-turbo', reversed=True)\n",
    "\n",
    "                if pd.isnull(row['generated_neutral_tweet_llama_2_70b_added']):\n",
    "                    df.at[i, 'generated_neutral_tweet_llama_2_70b_added'] = generate_tweet(claim, 'N', 'llama-70b')\n",
    "\n",
    "                if pd.isnull(row['generated_neutral_tweet_reversed_llama_2_70b_added']):\n",
    "                    df.at[i, 'generated_neutral_tweet_reversed_llama_2_70b_added'] = generate_tweet(claim, 'N', 'llama_2_70b', reversed=True)\n",
    "\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                time.sleep(10)\n",
    "                retry += 1\n",
    "                if retry >= 50:\n",
    "                    break\n",
    "\n",
    "    df.to_csv(save_path)\n",
    "\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    print(f\"Iteration: {i+1}, Runtime: {runtime} seconds\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
