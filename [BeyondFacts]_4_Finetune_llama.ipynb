{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0HQY-Gv_byW"
   },
   "outputs": [],
   "source": [
    "# This code is ran on Colab Pro with A100 (V100 is also possible)\n",
    "# Change paths accordingly\n",
    "\n",
    "!git clone https://github.com/hiyouga/LLaMA-Efficient-Tuning.git\n",
    "!pip install --upgrade pip\n",
    "!pip install bitsandbytes>=0.39.0\n",
    "!pip install -r LLaMA-Efficient-Tuning/requirements.txt\n",
    "!pip install trl==0.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jI1TYqdW_oZI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "efficient_finetuning_folder = \"LLaMA-Efficient-Tuning\"\n",
    "\n",
    "train_gpt_4_balanced = \"train_gpt-4_balanced.json\"\n",
    "train_gpt_4_balanced_reversed = \"train_gpt-4_balanced_reversed.json\"\n",
    "train_gpt_4_unbalanced = \"train_gpt-4_unbalanced.json\"\n",
    "train_gpt_4_unbalanced_reversed = \"train_gpt-4_unbalanced_reversed.json\"\n",
    "\n",
    "train_gpt_3_5_balanced = \"train_gpt-3_5_balanced.json\"\n",
    "train_gpt_3_5_balanced_reversed = \"train_gpt-3_5_balanced_reversed.json\"\n",
    "train_gpt_3_5_unbalanced = \"train_gpt-3_5_unbalanced.json\"\n",
    "train_gpt_3_5_unbalanced_reversed = \"train_gpt-3_5_unbalanced_reversed.json\"\n",
    "\n",
    "train_llama_balanced = \"train_llama_2_70b_balanced.json\"\n",
    "train_llama_balanced_reversed = \"train_llama_2_70b_balanced_reversed.json\"\n",
    "train_llama_unbalanced = \"train_llama_2_70b_unbalanced.json\"\n",
    "train_llama_unbalanced_reversed = \"train_llama_2_70b_unbalanced_reversed.json\"\n",
    "\n",
    "train_gpt_4_balanced_boosted = \"train_gpt-4_balanced_boosted.json\"\n",
    "\n",
    "test = \"test.json\"\n",
    "test_r = \"test_r.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EXTqhaOB_47s",
    "outputId": "9614e32c-ab25-49d4-e464-f31986713ffe"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def add_json_file(efficient_finetuning_folder, json_file_name):\n",
    "    # Replace {username} with your actual username\n",
    "    data_info_file = f\"{efficient_finetuning_folder}/data/dataset_info.json\"\n",
    "\n",
    "    # Load the data_info.json file\n",
    "    with open(data_info_file, 'r') as f:\n",
    "        data_info = json.load(f)\n",
    "\n",
    "    # Create a new key by removing the .json extension from the file name\n",
    "    new_key = json_file_name.replace('.json', '')\n",
    "\n",
    "    # Add the new key to the data_info dictionary\n",
    "    data_info[new_key] = {\n",
    "        'file_name': json_file_name\n",
    "    }\n",
    "\n",
    "    # Save the updated data_info.json file\n",
    "    with open(data_info_file, 'w') as f:\n",
    "        json.dump(data_info, f, indent=4)\n",
    "\n",
    "    print(f'Added {new_key} to data_info.json')\n",
    "\n",
    "add_json_file(efficient_finetuning_folder, train_gpt_4_balanced)\n",
    "add_json_file(efficient_finetuning_folder, train_gpt_4_balanced_reversed)\n",
    "add_json_file(efficient_finetuning_folder, train_gpt_4_unbalanced)\n",
    "add_json_file(efficient_finetuning_folder, train_gpt_4_unbalanced_reversed)\n",
    "\n",
    "add_json_file(efficient_finetuning_folder, train_gpt_3_5_balanced)\n",
    "add_json_file(efficient_finetuning_folder, train_gpt_3_5_balanced_reversed)\n",
    "add_json_file(efficient_finetuning_folder, train_gpt_3_5_unbalanced)\n",
    "add_json_file(efficient_finetuning_folder, train_gpt_3_5_unbalanced_reversed)\n",
    "\n",
    "add_json_file(efficient_finetuning_folder, train_llama_balanced)\n",
    "add_json_file(efficient_finetuning_folder, train_llama_balanced_reversed)\n",
    "add_json_file(efficient_finetuning_folder, train_llama_unbalanced)\n",
    "add_json_file(efficient_finetuning_folder, train_llama_unbalanced_reversed)\n",
    "\n",
    "add_json_file(efficient_finetuning_folder, train_gpt_4_balanced_boosted)\n",
    "\n",
    "add_json_file(efficient_finetuning_folder, test)\n",
    "add_json_file(efficient_finetuning_folder, test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9O9hWJsRpt7x",
    "outputId": "497d099d-94b2-4fe9-df24-976564c20dd4"
   },
   "outputs": [],
   "source": [
    "os.environ[\"TRANSFORMERS_CACHE\"] = \".cache/huggingface/\"\n",
    "!huggingface-cli login --token ### HUGGINGFACE API KEY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_-i1Wh7fChN"
   },
   "source": [
    "# FACT-GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30C-OeGJppHd"
   },
   "outputs": [],
   "source": [
    "def train_valid_llama(model_size, train_data):\n",
    "\n",
    "    command = f\"\"\"!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py \\\n",
    "        --stage sft \\\n",
    "        --model_name_or_path \"meta-llama/Llama-2-{model_size}-chat-hf\" \\\n",
    "        --do_train \\\n",
    "        --dataset \"{train_data}\" \\\n",
    "        --template \"default\" \\\n",
    "        --finetuning_type \"lora\" \\\n",
    "        --lora_target \"q_proj,v_proj\" \\\n",
    "        --output_dir \"data/train_valid_{model_size}_{train_data}\" \\\n",
    "        --overwrite_cache \\\n",
    "        --per_device_train_batch_size 4 \\\n",
    "        --gradient_accumulation_steps 4 \\\n",
    "        --lr_scheduler_type \"cosine\" \\\n",
    "        --logging_steps 1 \\\n",
    "        --save_steps 61 \\\n",
    "        --val_size 0.2 \\\n",
    "        --evaluation_strategy steps \\\n",
    "        --eval_steps 61 \\\n",
    "        --learning_rate \"5e-5\" \\\n",
    "        --num_train_epochs 3.0 \\\n",
    "        --plot_loss True \\\n",
    "        --fp16\"\"\"\n",
    "\n",
    "    print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sgcn4h_HhAZM"
   },
   "outputs": [],
   "source": [
    "def test_llama(model_size, train_data):\n",
    "\n",
    "    if 'reverse' in train_data:\n",
    "        suffix='_r'\n",
    "    else:\n",
    "        suffix=''\n",
    "\n",
    "    command = f\"\"\"!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py \\\n",
    "    --stage sft \\\n",
    "    --model_name_or_path 'meta-llama/Llama-2-{model_size}-chat-hf' \\\n",
    "    --do_predict \\\n",
    "    --dataset 'test{suffix}' \\\n",
    "    --template 'default' \\\n",
    "    --finetuning_type 'lora' \\\n",
    "    --checkpoint_dir 'data/train_valid_{model_size}_{train_data}' \\\n",
    "    --output_dir 'data/train_valid_{model_size}_{train_data}/test-endpoint' \\\n",
    "    --per_device_eval_batch_size 8 \\\n",
    "    --max_samples 10000 \\\n",
    "    --temperature 0.01 \\\n",
    "    --top_p 0.01 \\\n",
    "    --predict_with_generate\"\"\"\n",
    "\n",
    "    print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAiwGBmgitr6"
   },
   "outputs": [],
   "source": [
    "def test_llama_checkpoint(model_size, train_data, checkpoint):\n",
    "\n",
    "    if 'reverse' in train_data:\n",
    "        suffix='_r'\n",
    "    else:\n",
    "        suffix=''\n",
    "\n",
    "    command = f\"\"\"!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py \\\n",
    "    --stage sft \\\n",
    "    --model_name_or_path 'meta-llama/Llama-2-{model_size}-chat-hf' \\\n",
    "    --do_predict \\\n",
    "    --dataset 'test{suffix}' \\\n",
    "    --template 'default' \\\n",
    "    --finetuning_type 'lora' \\\n",
    "    --checkpoint_dir 'data/train_valid_{model_size}_{train_data}/checkpoint-{checkpoint}' \\\n",
    "    --output_dir 'data/train_valid_{model_size}_{train_data}/test-{checkpoint}' \\\n",
    "    --per_device_eval_batch_size 8 \\\n",
    "    --max_samples 10000 \\\n",
    "    --temperature 0.01 \\\n",
    "    --top_p 0.01 \\\n",
    "    --predict_with_generate\"\"\"\n",
    "\n",
    "    print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cm8mA078jA-v"
   },
   "source": [
    "### Train-test 13b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sbhjFzYKNIL3",
    "outputId": "e4e7ccdb-c80e-4883-b665-8f38e33e8e6b"
   },
   "outputs": [],
   "source": [
    "train_valid_llama('13b', 'train_gpt-4_balanced')\n",
    "train_valid_llama('13b', 'train_gpt-4_balanced_reversed')\n",
    "train_valid_llama('13b', 'train_gpt-4_unbalanced')\n",
    "train_valid_llama('13b', 'train_gpt-4_unbalanced_reversed')\n",
    "\n",
    "train_valid_llama('13b', 'train_gpt-3_5_balanced')\n",
    "train_valid_llama('13b', 'train_gpt-3_5_balanced_reversed')\n",
    "train_valid_llama('13b', 'train_gpt-3_5_unbalanced')\n",
    "train_valid_llama('13b', 'train_gpt-3_5_unbalanced_reversed')\n",
    "\n",
    "train_valid_llama('13b', 'train_llama_2_70b_unbalanced')\n",
    "train_valid_llama('13b', 'train_llama_2_70b_unbalanced_reversed')\n",
    "train_valid_llama('13b', 'train_llama_2_70b_balanced')\n",
    "train_valid_llama('13b', 'train_llama_2_70b_balanced_reversed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ByUalVn_jEBP",
    "outputId": "b862f1a0-84f7-410b-b95f-ea8416aa1972"
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_gpt-4_balanced\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_13b_train_gpt-4_balanced\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_gpt-4_balanced_reversed\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_13b_train_gpt-4_balanced_reversed\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_gpt-4_unbalanced\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_13b_train_gpt-4_unbalanced\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_gpt-4_unbalanced_reversed\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_13b_train_gpt-4_unbalanced_reversed\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_gpt-3_5_balanced\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_13b_train_gpt-3_5_balanced\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_gpt-3_5_balanced_reversed\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_13b_train_gpt-3_5_balanced_reversed\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_gpt-3_5_unbalanced\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_13b_train_gpt-3_5_unbalanced\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_gpt-3_5_unbalanced_reversed\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_13b_train_gpt-3_5_unbalanced_reversed\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_llama_2_70b_unbalanced\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_13b_train_llama_2_70b_unbalanced\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_llama_2_70b_unbalanced_reversed\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_13b_train_llama_2_70b_unbalanced_reversed\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_llama_2_70b_balanced\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_13b_train_llama_2_70b_balanced\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_llama_2_70b_balanced_reversed\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_13b_train_llama_2_70b_balanced_reversed\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIBKPRPHhMdr",
    "outputId": "47930102-f610-4a84-8502-daab1af31922"
   },
   "outputs": [],
   "source": [
    "test_llama('13b', 'train_gpt-4_balanced')\n",
    "test_llama('13b', 'train_gpt-4_balanced_reversed')\n",
    "test_llama('13b', 'train_gpt-4_unbalanced')\n",
    "test_llama('13b', 'train_gpt-4_unbalanced_reversed')\n",
    "\n",
    "test_llama('13b', 'train_gpt-3_5_balanced')\n",
    "test_llama('13b', 'train_gpt-3_5_balanced_reversed')\n",
    "test_llama('13b', 'train_gpt-3_5_unbalanced')\n",
    "test_llama('13b', 'train_gpt-3_5_unbalanced_reversed')\n",
    "\n",
    "test_llama('13b', 'train_llama_2_70b_unbalanced')\n",
    "test_llama('13b', 'train_llama_2_70b_unbalanced_reversed')\n",
    "test_llama('13b', 'train_llama_2_70b_balanced')\n",
    "test_llama('13b', 'train_llama_2_70b_balanced_reversed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLH-47J6j_Yr",
    "outputId": "3b5ad564-fe3f-4fb8-b011-2d04307b08bc"
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AoXWi79CKRkc",
    "outputId": "a6c4d4c1-6550-442d-9452-24b915020b78"
   },
   "outputs": [],
   "source": [
    "train_valid_llama('7b', 'train_gpt-4_balanced')\n",
    "train_valid_llama('7b', 'train_gpt-4_balanced_reversed')\n",
    "train_valid_llama('7b', 'train_gpt-4_unbalanced')\n",
    "train_valid_llama('7b', 'train_gpt-4_unbalanced_reversed')\n",
    "\n",
    "train_valid_llama('7b', 'train_gpt-3_5_balanced')\n",
    "train_valid_llama('7b', 'train_gpt-3_5_balanced_reversed')\n",
    "train_valid_llama('7b', 'train_gpt-3_5_unbalanced')\n",
    "train_valid_llama('7b', 'train_gpt-3_5_unbalanced_reversed')\n",
    "\n",
    "train_valid_llama('7b', 'train_llama_2_70b_unbalanced')\n",
    "train_valid_llama('7b', 'train_llama_2_70b_unbalanced_reversed')\n",
    "train_valid_llama('7b', 'train_llama_2_70b_balanced')\n",
    "train_valid_llama('7b', 'train_llama_2_70b_balanced_reversed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrloBGMZkBoH",
    "outputId": "52aa1bd7-1d01-446f-93e3-f2928a8ddb9b"
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_gpt-4_balanced\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_7b_train_gpt-4_balanced\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_gpt-4_balanced_reversed\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_7b_train_gpt-4_balanced_reversed\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_gpt-4_unbalanced\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_7b_train_gpt-4_unbalanced\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_gpt-4_unbalanced_reversed\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_7b_train_gpt-4_unbalanced_reversed\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_gpt-3_5_balanced\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_7b_train_gpt-3_5_balanced\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_gpt-3_5_balanced_reversed\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_7b_train_gpt-3_5_balanced_reversed\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_gpt-3_5_unbalanced\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_7b_train_gpt-3_5_unbalanced\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_gpt-3_5_unbalanced_reversed\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_7b_train_gpt-3_5_unbalanced_reversed\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_llama_2_70b_unbalanced\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_7b_train_llama_2_70b_unbalanced\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_llama_2_70b_unbalanced_reversed\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_7b_train_llama_2_70b_unbalanced_reversed\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_llama_2_70b_balanced\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_7b_train_llama_2_70b_balanced\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_llama_2_70b_balanced_reversed\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"data/train_valid_7b_train_llama_2_70b_balanced_reversed\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8F710lfqhcfb",
    "outputId": "fd0592fe-5324-4a2a-8c5f-706b1353d87a"
   },
   "outputs": [],
   "source": [
    "test_llama('7b', 'train_gpt-4_balanced')\n",
    "test_llama('7b', 'train_gpt-4_balanced_reversed')\n",
    "test_llama('7b', 'train_gpt-4_unbalanced')\n",
    "test_llama('7b', 'train_gpt-4_unbalanced_reversed')\n",
    "\n",
    "test_llama('7b', 'train_gpt-3_5_balanced')\n",
    "test_llama('7b', 'train_gpt-3_5_balanced_reversed')\n",
    "test_llama('7b', 'train_gpt-3_5_unbalanced')\n",
    "test_llama('7b', 'train_gpt-3_5_unbalanced_reversed')\n",
    "\n",
    "test_llama('7b', 'train_llama_2_70b_unbalanced')\n",
    "test_llama('7b', 'train_llama_2_70b_unbalanced_reversed')\n",
    "test_llama('7b', 'train_llama_2_70b_balanced')\n",
    "test_llama('7b', 'train_llama_2_70b_balanced_reversed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qdzbXRe5kDlD",
    "outputId": "b50e0447-4f5e-4cb0-e654-31ac6d81ebe8"
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKKrylQNpWEA"
   },
   "source": [
    "### Test-checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JaGM42Y6sIxl",
    "outputId": "c7b5106e-f773-4a80-97f3-91cf535eea75"
   },
   "outputs": [],
   "source": [
    "for checkpoint in range(61, 550, 61):\n",
    "    test_llama_checkpoint('13b', 'train_gpt-4_balanced', checkpoint)\n",
    "    test_llama_checkpoint('13b', 'train_gpt-4_balanced_reversed', checkpoint)\n",
    "    test_llama_checkpoint('13b', 'train_gpt-4_unbalanced', checkpoint)\n",
    "    test_llama_checkpoint('13b', 'train_gpt-4_unbalanced_reversed', checkpoint)\n",
    "\n",
    "for checkpoint in range(61, 550, 61):\n",
    "    test_llama_checkpoint('13b', 'train_gpt-3_5_balanced', checkpoint)\n",
    "    test_llama_checkpoint('13b', 'train_gpt-3_5_balanced_reversed', checkpoint)\n",
    "    test_llama_checkpoint('13b', 'train_gpt-3_5_unbalanced', checkpoint)\n",
    "    test_llama_checkpoint('13b', 'train_gpt-3_5_unbalanced_reversed', checkpoint)\n",
    "\n",
    "for checkpoint in range(61, 550, 61):\n",
    "    test_llama_checkpoint('13b', 'train_llama_2_70b_unbalanced', checkpoint)\n",
    "    test_llama_checkpoint('13b', 'train_llama_2_70b_unbalanced_reversed', checkpoint)\n",
    "    test_llama_checkpoint('13b', 'train_llama_2_70b_balanced', checkpoint)\n",
    "    test_llama_checkpoint('13b', 'train_llama_2_70b_balanced_reversed', checkpoint)\n",
    "\n",
    "for checkpoint in range(61, 550, 61):\n",
    "    test_llama_checkpoint('7b', 'train_gpt-4_balanced', checkpoint)\n",
    "    test_llama_checkpoint('7b', 'train_gpt-4_balanced_reversed', checkpoint)\n",
    "    test_llama_checkpoint('7b', 'train_gpt-4_unbalanced', checkpoint)\n",
    "    test_llama_checkpoint('7b', 'train_gpt-4_unbalanced_reversed', checkpoint)\n",
    "\n",
    "for checkpoint in range(61, 550, 61):\n",
    "    test_llama_checkpoint('7b', 'train_gpt-3_5_balanced', checkpoint)\n",
    "    test_llama_checkpoint('7b', 'train_gpt-3_5_balanced_reversed', checkpoint)\n",
    "    test_llama_checkpoint('7b', 'train_gpt-3_5_unbalanced', checkpoint)\n",
    "    test_llama_checkpoint('7b', 'train_gpt-3_5_unbalanced_reversed', checkpoint)\n",
    "\n",
    "for checkpoint in range(61, 550, 61):\n",
    "    test_llama_checkpoint('7b', 'train_llama_2_70b_unbalanced', checkpoint)\n",
    "    test_llama_checkpoint('7b', 'train_llama_2_70b_unbalanced_reversed', checkpoint)\n",
    "    test_llama_checkpoint('7b', 'train_llama_2_70b_balanced', checkpoint)\n",
    "    test_llama_checkpoint('7b', 'train_llama_2_70b_balanced_reversed', checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rf3Ak3lkGgz",
    "outputId": "e965659a-4544-4686-895e-ec7650df8563"
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced/checkpoint-61'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/checkpoint-61'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced/checkpoint-61'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/checkpoint-61'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced/checkpoint-122'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/checkpoint-122'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced/checkpoint-122'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/checkpoint-122'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced/checkpoint-183'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/checkpoint-183'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced/checkpoint-183'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/checkpoint-183'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced/checkpoint-244'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/checkpoint-244'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced/checkpoint-244'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/checkpoint-244'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced/checkpoint-305'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/checkpoint-305'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced/checkpoint-305'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/checkpoint-305'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced/checkpoint-366'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/checkpoint-366'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced/checkpoint-366'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/checkpoint-366'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced/checkpoint-427'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/checkpoint-427'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced/checkpoint-427'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/checkpoint-427'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced/checkpoint-488'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/checkpoint-488'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced/checkpoint-488'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/checkpoint-488'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced/checkpoint-549'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/checkpoint-549'     --output_dir 'data/train_valid_13b_train_gpt-4_balanced_reversed/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced/checkpoint-549'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/checkpoint-549'     --output_dir 'data/train_valid_13b_train_gpt-4_unbalanced_reversed/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced/checkpoint-61'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/checkpoint-61'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/checkpoint-61'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/checkpoint-61'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced/checkpoint-122'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/checkpoint-122'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/checkpoint-122'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/checkpoint-122'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced/checkpoint-183'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/checkpoint-183'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/checkpoint-183'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/checkpoint-183'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced/checkpoint-244'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/checkpoint-244'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/checkpoint-244'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/checkpoint-244'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced/checkpoint-305'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/checkpoint-305'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/checkpoint-305'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/checkpoint-305'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced/checkpoint-366'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/checkpoint-366'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/checkpoint-366'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/checkpoint-366'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced/checkpoint-427'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/checkpoint-427'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/checkpoint-427'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/checkpoint-427'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced/checkpoint-488'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/checkpoint-488'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/checkpoint-488'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/checkpoint-488'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced/checkpoint-549'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/checkpoint-549'     --output_dir 'data/train_valid_13b_train_gpt-3_5_balanced_reversed/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/checkpoint-549'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/checkpoint-549'     --output_dir 'data/train_valid_13b_train_gpt-3_5_unbalanced_reversed/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/checkpoint-61'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/checkpoint-61'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced/checkpoint-61'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/checkpoint-61'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/checkpoint-122'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/checkpoint-122'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced/checkpoint-122'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/checkpoint-122'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/checkpoint-183'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/checkpoint-183'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced/checkpoint-183'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/checkpoint-183'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/checkpoint-244'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/checkpoint-244'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced/checkpoint-244'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/checkpoint-244'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/checkpoint-305'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/checkpoint-305'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced/checkpoint-305'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/checkpoint-305'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/checkpoint-366'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/checkpoint-366'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced/checkpoint-366'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/checkpoint-366'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/checkpoint-427'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/checkpoint-427'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced/checkpoint-427'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/checkpoint-427'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/checkpoint-488'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/checkpoint-488'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced/checkpoint-488'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/checkpoint-488'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/checkpoint-549'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/checkpoint-549'     --output_dir 'data/train_valid_13b_train_llama_2_70b_unbalanced_reversed/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced/checkpoint-549'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/checkpoint-549'     --output_dir 'data/train_valid_13b_train_llama_2_70b_balanced_reversed/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced/checkpoint-61'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/checkpoint-61'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced/checkpoint-61'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/checkpoint-61'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced/checkpoint-122'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/checkpoint-122'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced/checkpoint-122'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/checkpoint-122'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced/checkpoint-183'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/checkpoint-183'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced/checkpoint-183'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/checkpoint-183'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced/checkpoint-244'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/checkpoint-244'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced/checkpoint-244'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/checkpoint-244'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced/checkpoint-305'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/checkpoint-305'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced/checkpoint-305'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/checkpoint-305'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced/checkpoint-366'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/checkpoint-366'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced/checkpoint-366'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/checkpoint-366'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced/checkpoint-427'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/checkpoint-427'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced/checkpoint-427'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/checkpoint-427'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced/checkpoint-488'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/checkpoint-488'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced/checkpoint-488'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/checkpoint-488'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced/checkpoint-549'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/checkpoint-549'     --output_dir 'data/train_valid_7b_train_gpt-4_balanced_reversed/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced/checkpoint-549'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/checkpoint-549'     --output_dir 'data/train_valid_7b_train_gpt-4_unbalanced_reversed/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced/checkpoint-61'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/checkpoint-61'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/checkpoint-61'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/checkpoint-61'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced/checkpoint-122'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/checkpoint-122'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/checkpoint-122'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/checkpoint-122'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced/checkpoint-183'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/checkpoint-183'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/checkpoint-183'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/checkpoint-183'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced/checkpoint-244'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/checkpoint-244'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/checkpoint-244'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/checkpoint-244'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced/checkpoint-305'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/checkpoint-305'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/checkpoint-305'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/checkpoint-305'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced/checkpoint-366'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/checkpoint-366'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/checkpoint-366'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/checkpoint-366'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced/checkpoint-427'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/checkpoint-427'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/checkpoint-427'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/checkpoint-427'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced/checkpoint-488'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/checkpoint-488'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/checkpoint-488'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/checkpoint-488'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced/checkpoint-549'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/checkpoint-549'     --output_dir 'data/train_valid_7b_train_gpt-3_5_balanced_reversed/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/checkpoint-549'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/checkpoint-549'     --output_dir 'data/train_valid_7b_train_gpt-3_5_unbalanced_reversed/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/checkpoint-61'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/checkpoint-61'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced/checkpoint-61'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/checkpoint-61'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/test-61'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/checkpoint-122'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/checkpoint-122'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced/checkpoint-122'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/checkpoint-122'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/test-122'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/checkpoint-183'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/checkpoint-183'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced/checkpoint-183'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/checkpoint-183'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/test-183'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/checkpoint-244'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/checkpoint-244'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced/checkpoint-244'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/checkpoint-244'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/test-244'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/checkpoint-305'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/checkpoint-305'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced/checkpoint-305'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/checkpoint-305'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/test-305'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/checkpoint-366'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/checkpoint-366'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced/checkpoint-366'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/checkpoint-366'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/test-366'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/checkpoint-427'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/checkpoint-427'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced/checkpoint-427'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/checkpoint-427'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/test-427'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/checkpoint-488'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/checkpoint-488'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced/checkpoint-488'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/checkpoint-488'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/test-488'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/checkpoint-549'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/checkpoint-549'     --output_dir 'data/train_valid_7b_train_llama_2_70b_unbalanced_reversed/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced/checkpoint-549'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
    "!CUDA_VISIBLE_DEVICES=0 python LLaMA-Efficient-Tuning/src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test_r'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/checkpoint-549'     --output_dir 'data/train_valid_7b_train_llama_2_70b_balanced_reversed/test-549'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
